{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "# Draw insights from car accident reports\n",
    "This notebook shows you how to analyze car vehicle accidents based on accident reports for New York. The analysis steps in the notebook show how you can use the information about accidents to learn more about the possible causes for collisions. You will learn how to install additional Python packages, how to add external PySpark modules, and how to perform descriptive data analysis.\n",
    "\n",
    "This notebook runs on Python 2 with Spark 2.0.2\n",
    "\n",
    "## Load data\n",
    "\n",
    "This data set covers all reported vehicle collisions in New York starting in July 2012 until the end of December 2017 and contains detailed information about the incidents.\n",
    "\n",
    "The file is already part of the Tutorial project. Accesssing the data is as simple as reading the `csv` file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "collisions = spark.read.csv('../datasets/NYPD_Motor_Vehicle_Collisions.csv', header='true', inferSchema='true') \n",
    "collisions.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Caching the data\n",
    "Here we use the `cache()` method to tell Spark that we are reusing the data so if it can be cached we avoid the cost of re-reading from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions.cache()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Printing basic information\n",
    "The next cell prints the number of records in the DataFrame and the data set schema.<br/>\n",
    "Note that there are multiple ways to print results.\n",
    "\n",
    "The schema is useful to see the data organization and the types of the attributes. the `printSchema` method is a good one to remember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Print the number of records and display the DataFrame schema\n",
    "print(\"Records: {}\".format(collisions.count()))\n",
    "collisions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load visualization packages\n",
    "\n",
    "To plot data, this notebook will use the following two packages, which you need to import or install:\n",
    "\n",
    "- [Matplotlib](http://matplotlib.org/), a basic plotting library for Python\n",
    "- [Seaborn](http://stanford.edu/~mwaskom/software/seaborn/), a statistical data visualization library\n",
    "\n",
    "The `seaborn` package is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\n",
    "\n",
    "The import commands are there to make these packages available.\n",
    "\n",
    "The Pandas package was mentioned in the first tutorial. It is a Python library used for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.patches lets us create colored patches, which we can use for legends in plots\n",
    "import matplotlib.patches as mpatches\n",
    "# seaborn also builds on matplotlib and adds graphical features and new plot types\n",
    "# adjust settings\n",
    "# The inline statement insures that the plot will show in the cell output. Look at the documentation for more information\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\")\n",
    "plt.rcParams['figure.figsize'] = (15, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Extracting the desired information\n",
    "The following cell extracts records that have a latitude different than 0 and a specific set of attributes into a Pandas DataFrame.\n",
    "\n",
    "A Panda DataFrame is a local structure. this means that all the data extracted from the Spark DataFram must fit in the local memory.\n",
    "\n",
    "In here we see some changes to column names, and changes in data types (from double to float).<br/>\n",
    "Finally, additional Pandas DataFramdes are created based on if people were killed or injured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_df = collisions\n",
    "collisions_pd = collisions_df[collisions_df['LATITUDE'] != 0][['LATITUDE', 'LONGITUDE', 'DATE', 'TIME',\n",
    "                                                               'BOROUGH', 'ON STREET NAME', 'CROSS STREET NAME',\n",
    "                                                               'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
    "                                                               'CONTRIBUTING FACTOR VEHICLE 1']].toPandas()\n",
    "\n",
    "collisions_pd.columns = ['Latitude', 'Longitude', 'Date', 'Time', 'Borough', 'On Street',\n",
    "                         'Cross Street', 'Persons Injured', 'Persons Killed', 'Contributing Factor']\n",
    "\n",
    "collisions_pd['Latitude'] = collisions_pd['Latitude'].astype(float)\n",
    "collisions_pd['Longitude'] = collisions_pd['Longitude'].astype(float)\n",
    "collisions_pd['Persons Killed'] = collisions_pd['Persons Killed'].astype(float)\n",
    "collisions_pd['Persons Injured'] = collisions_pd['Persons Injured'].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "#divide dataset into accident categories: fatal, non-fatal but with injuries, none of the above\n",
    "killed_pd = collisions_pd[collisions_pd['Persons Killed']!=0]\n",
    "injured_pd = collisions_pd[np.logical_and(collisions_pd['Persons Injured']!=0, collisions_pd['Persons Killed']==0)]\n",
    "nothing_pd = collisions_pd[np.logical_and(collisions_pd['Persons Killed']==0, collisions_pd['Persons Injured']==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create an explorative scatter plot of the data\n",
    "Using an explorative scatter plot is a way to analyze certain characteristics of the data set. \n",
    "\n",
    "Create an intial explorative scatter plot of all collisions by using the latitude and longitude information in the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create scatterplots\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(collisions_pd.Longitude, collisions_pd.Latitude, alpha=0.05, s=4, color='darkseagreen')\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Motor Vehicle Collisions in New York City', size=25)\n",
    "plt.xlim((-74.26,-73.7))\n",
    "plt.ylim((40.5,40.92))\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Although this is not a real street map of New York City, the scatter plot dots roughly correspond to the street grid. You see very few collisions in Central Park or on bridges, as opposed to street crossings and curves, where there is a noticeably higher density of collisions.\n",
    "\n",
    "### Enhance the scatter plot with information about city boroughs\n",
    "Now add information about the city boroughs and use a different color to depict each borough on the scatter plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "manhattan = collisions_pd[collisions_pd['Borough']=='MANHATTAN']\n",
    "bronx = collisions_pd[collisions_pd['Borough']=='BRONX']\n",
    "brooklyn = collisions_pd[collisions_pd['Borough']=='BROOKLYN']\n",
    "staten = collisions_pd[collisions_pd['Borough']=='STATEN ISLAND']\n",
    "queens = collisions_pd[collisions_pd['Borough']=='QUEENS']\n",
    "\n",
    "\n",
    "#create scatterplots\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(manhattan.Longitude, manhattan.Latitude, s=1, color='blue', marker ='.')\n",
    "plt.scatter(bronx.Longitude, bronx.Latitude, s=1, color='yellow', marker ='.')\n",
    "plt.scatter(brooklyn.Longitude, brooklyn.Latitude, color='red', s=1, marker ='.')\n",
    "plt.scatter(staten.Longitude, staten.Latitude, s=1, color='green', marker ='.')\n",
    "plt.scatter(queens.Longitude, queens.Latitude, s=1, color='black', marker ='.')\n",
    "\n",
    "#create legend\n",
    "blue_patch = mpatches.Patch(label='Manhattan', color='blue')\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='Bronx')\n",
    "red_patch = mpatches.Patch(color='red', label='Brooklyn')\n",
    "green_patch = mpatches.Patch(color='green', label='Staten Island')\n",
    "black_patch = mpatches.Patch(color='black', label='Queens')\n",
    "plt.legend([blue_patch, yellow_patch, red_patch, green_patch, black_patch],\n",
    "           ('Manhattan', 'Bronx', 'Brooklyn', 'Staten Island', 'Queens'), \n",
    "           loc='upper left', prop={'size':20})\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Motor Vehicle Collisions in New York City by borough', size=20)\n",
    "plt.xlim((-74.26,-73.7))\n",
    "plt.ylim((40.5,40.92))\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Which neighborhoods have the highest total number of crashes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "borough = collisions_df.groupBy('BOROUGH').count().sort('count').toPandas() # .iloc[1:,:]\n",
    "borough['BOROUGH'].fillna('NONE', inplace=True)\n",
    "colors = ['g','0.75','y','k','b','r']\n",
    "borough.sort_values(by='count', ascending=True)['count'].plot.barh(color=colors)\n",
    "plt.xlabel('Collisions')\n",
    "plt.ylabel('Borough')\n",
    "plt.title('Total Number of Collisions by Borough', size=15)\n",
    "plt.yticks(range(0,6),borough['BOROUGH'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### The bar graph clearly shows that the most collisions happen in Brooklyn and the least on Staten Island."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# List the array that includes the count of accident per borough (NONE indicates that the borough was blank in the record)\n",
    "borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Enhance the scatter plot to identify the accidents severity\n",
    "We draw from Pandas DataFrames we created earlier to plot the severity in different color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#adjust settings\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "#create scatterplots\n",
    "plt.scatter(nothing_pd.Longitude, nothing_pd.Latitude, alpha=0.04, s=1, color='blue')\n",
    "plt.scatter(injured_pd.Longitude, injured_pd.Latitude, alpha=0.1, s=1, color='yellow')\n",
    "plt.scatter(killed_pd.Longitude, killed_pd.Latitude, color='red', s=5)\n",
    "\n",
    "#create legend\n",
    "blue_patch = mpatches.Patch( label='car body damage', alpha=0.2, color='blue')\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='personal injury', alpha=0.5)\n",
    "red_patch = mpatches.Patch(color='red', label='lethal accidents')\n",
    "plt.legend([blue_patch, yellow_patch, red_patch],('car body damage', 'personal injury', 'fatal accidents'), \n",
    "           loc='upper left', prop={'size':20})\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Severity of Motor Vehicle Collisions in New York City', size=20)\n",
    "plt.xlim((-74.26,-73.7))\n",
    "plt.ylim((40.5,40.92))\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "plt.savefig('anothertry.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The resulting scatter plot shows that there are fatal accident hot spots throughout the city. You can see that in some areas car body damage is prevalent, while in other areas personal injuries happen more often.\n",
    "\n",
    "## Clean and shape the data\n",
    "After using scatter plots to analyze certain characteristics of the raw data set, you will now learn how to clean and shape the data set to enable more plotting and further analysis. \n",
    "\n",
    "Begin by looking at the column names again to better assess which information you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_header_list = collisions.columns[:-4] # all columns except the last 4 (see printSchema above)\n",
    "# Remove a few additional columns form the list\n",
    "collisions_header_list.remove(\"CONTRIBUTING FACTOR VEHICLE 3\")\n",
    "collisions_header_list.remove(\"CONTRIBUTING FACTOR VEHICLE 4\")\n",
    "collisions_header_list.remove(\"CONTRIBUTING FACTOR VEHICLE 5\")\n",
    "# Take only records that include the \"ON STREET NAME\" and \"BOROUGH\" and return only the desired attributes\n",
    "collisions_df = collisions_df.dropna(how='any', subset=['ON STREET NAME', 'BOROUGH'])[collisions_header_list]\n",
    "# Display statistics on the resulting DataFrame, specially the number of non-null values in each column\n",
    "collisions_df.toPandas().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Spatial and temporal normalization by using Spark\n",
    "\n",
    "To obtain a consistent representation of the spatial and temporal information about collisions, you have to normalize the data. Normalization is the process of organizing the columns (attributes) and tables (relations) to minimize data redundancy. This step will help you in future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "delchars = ''.join(c for c in map(chr, range(256)) if not c.isalnum())\n",
    "deltable = dict((ord(char), None) for char in delchars) # Python2 unicode\n",
    "normalization_code = {\n",
    "    'avenue':'av',\n",
    "    'ave':'av',\n",
    "    'avnue': 'av',\n",
    "    'street': 'st',\n",
    "    'road': 'rd',\n",
    "    'boulevard': 'blvd',\n",
    "    'place': 'pl',\n",
    "    'plaza': 'pl',\n",
    "    'square': 'sq',\n",
    "    'drive': 'dr',\n",
    "    'lane': 'ln',\n",
    "    'parkway': 'pkwy',\n",
    "    'turnpike': 'tp',\n",
    "    'terrace': 'ter',\n",
    "    '1st': '1',\n",
    "    '2nd':'2',\n",
    "    '3rd': '3',\n",
    "    '1th': '1',\n",
    "    '2th': '2',\n",
    "    '3th': '3',\n",
    "    '4th': '4',\n",
    "    '5th': '5',\n",
    "    '6th': '6',\n",
    "    '7th': '7', \n",
    "    '8th': '8',\n",
    "    '9th': '9',\n",
    "    '0th': '0',\n",
    "    'west ': 'w ',\n",
    "    'north ': 'n ',\n",
    "    'east ': 'e ',\n",
    "    'south ': 's ',\n",
    "}\n",
    "def normalize_street(s):\n",
    "    # Lowercase\n",
    "    s = s.lower()\n",
    "\n",
    "    # Delete all non-alphanumeric characters\n",
    "    if isinstance(s, unicode):\n",
    "        s = s.translate(deltable)\n",
    "    else:\n",
    "        s = s.translate(None, delchars) # Python 2\n",
    "\n",
    "    # Replace common abbreviations\n",
    "    for k in sorted(normalization_code.keys()):\n",
    "        s = s.replace(k, normalization_code[k])\n",
    "\n",
    "    # Only keep ascii chars\n",
    "    s = s.encode('ascii', errors='ignore').decode()\n",
    "\n",
    "    return s\n",
    "\n",
    "def row_parser(row):\n",
    "    from datetime import datetime\n",
    "    \n",
    "    \"\"\"\n",
    "    Spatial and Temporal Normalization\n",
    "    Returns the location, borough, year, month, day, hour; removes nonalphanumeric characters\n",
    "    \"\"\"\n",
    "    # create a row dictionary\n",
    "    row_dict = row.asDict()\n",
    "    \n",
    "    # temporal\n",
    "    ## date\n",
    "    temp = row_dict['DATE']\n",
    "    hr = row_dict['TIME'].split(\":\")[0]\n",
    "    try:\n",
    "        a = datetime.strptime(temp+\" \"+hr, '%m/%d/%Y %H')\n",
    "        dates =  [a]\n",
    "    except:\n",
    "        a = datetime.now()\n",
    "        dates = [a]\n",
    "    \n",
    "    # location and borough\n",
    "    location = normalize_street(row_dict['ON STREET NAME'])\n",
    "    borough = row_dict['BOROUGH'].lower()\n",
    "    \n",
    "    \n",
    "    # other cols\n",
    "    others = [row_dict[column] for column in collisions_header_list\n",
    "             if column not in [\"ON STREET NAME\", \"OFF STREET NAME\", \"CROSS STREET NAME\", \"BOROUGH\", \"DATE\", \"TIME\"]]\n",
    "\n",
    "       \n",
    "\n",
    "    # return everything together\n",
    "    return dates + [location] + [borough] + others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Now apply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_out_row = Row(*([\"Time\", \"Street\", \"Borough\"] + [c for c in collisions_header_list\n",
    "                      if c not in [\"ON STREET NAME\", \"OFF STREET NAME\", \"CROSS STREET NAME\", \"BOROUGH\", \"DATE\", \"TIME\"]]))\n",
    "collisions_out_index = list(collisions_out_row)\n",
    "\n",
    "collisions_out = collisions_df.rdd.map(\n",
    "    lambda row: collisions_out_row(*(row_parser(row)))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Statistics on our resulting DataFrame\n",
    "collisions_out.toPandas().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Investigating data attributes\n",
    "You can draw information from your data by examining the attributes in the data set and finding out how useful they are. \n",
    "\n",
    "Begin by plotting the contributing factors of an accident:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "collisions_out_df = collisions_out\n",
    "\n",
    "factor = collisions_out_df.groupBy('CONTRIBUTING FACTOR VEHICLE 1').count().sort(desc('count')).toPandas()\n",
    "factor = factor[0:20].sort_index(ascending=False)\n",
    "factor.plot(kind='barh', legend=False, color='blue', figsize=(14,10))\n",
    "plt.title('Composition of: ' + 'CONTRIBUTING FACTOR VEHICLE 1', size=20)\n",
    "plt.xlabel('Count')\n",
    "plt.yticks(range(len(factor))[::-1], factor['CONTRIBUTING FACTOR VEHICLE 1'][::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Running the code cell above shows you that the contributing factor can't be specified in most cases. However, factors like distraction, failure to yield right-of-way, and fatigue could have an influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sorting accidents by vehicle type\n",
    "The data set has entries for a large number of car types. To avoid inconclusive results because the  number of car types is too large, regroup the car types into main categories like auto, bus, truck, taxi or other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vehicletypecode, vehicletypecoderange = 'VEHICLE TYPE CODE ', range(1,6)\n",
    "grouping = {\n",
    "    'TAXI': 'Taxi',\n",
    "    'AMBULANCE': 'Other',\n",
    "    'BICYCLE': 'Other',\n",
    "    'BUS': 'Bus',\n",
    "    'FIRE TRUCK': 'Other', \n",
    "    'LARGE COM VEH(6 OR MORE TIRES)': 'Truck',\n",
    "    'LIVERY VEHICLE': 'Truck',\n",
    "    'MOTORCYCLE': 'Other', \n",
    "    'OTHER': 'Other',\n",
    "    'PASSENGER VEHICLE': 'Auto',\n",
    "    'PICK-UP TRUCK': 'Other',\n",
    "    'PEDICAB': 'Other', \n",
    "    'SCOOTER': 'Other',\n",
    "    'SMALL COM VEH(4 TIRES) ': 'Truck',\n",
    "    'SPORT UTILITY / STATION WAGON': 'Auto', \n",
    "    'UNKNOWN': 'Other',\n",
    "    'VAN': 'Auto',\n",
    "    'UNSPECIFIED': 'Other',\n",
    "    None: None\n",
    "}\n",
    "# Over time, additional groups have been used. The following function makes sure that any unknown group then falls under \"Other\"\n",
    "def vtype_group(vtype):\n",
    "    if grouping.has_key(vtype) :\n",
    "        return grouping[vtype]\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "collisions_out_categories = collisions_out.rdd.map(lambda row:\n",
    "                   collisions_out_row(*[vtype_group(row[i]) if collisions_out_index[i].startswith(\"VEHICLE TYPE CODE\")\n",
    "                                                    else row[i] for i in range(len(row))])\n",
    "                 ).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_transformed_row = Row(*([\"Time\", \"Street\", \"Borough\", \"Injured\",\n",
    "                                                \"Killed\", \"Auto\", \"Bus\",\n",
    "                                                \"Truck\", \"Taxi\", \"Other\", ]))\n",
    "\n",
    "def transform_involved(row):\n",
    "    counts = Counter([row[i] for i in range(len(row)) if collisions_out_index[i].startswith(\"VEHICLE TYPE CODE\")])\n",
    "    return collisions_transformed_row(*([row.asDict()[c] for c in [\"Time\", \"Street\", \"Borough\",\n",
    "                                                                      \"NUMBER OF PERSONS INJURED\",\n",
    "                                                                      \"NUMBER OF PERSONS KILLED\"]] + \n",
    "                                       [counts[x] if x in counts else 0\n",
    "                                           for x in ['Auto', 'Bus','Truck', 'Taxi', 'Other']]))\n",
    "\n",
    "collisions_transformed = collisions_out_categories.rdd.map(transform_involved).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_transformed_boolean_row = Row(*([\"Time\", \"Street\", \"Borough\",\n",
    "                                                        \"AccidentsWithInjuries\",\n",
    "                                                        \"AccidentswithDeaths\", \"Auto\", \"Bus\",\n",
    "                                                        \"Truck\", \"Taxi\", \"Other\",\n",
    "                                                        \"Injured\", \"Killed\"]))\n",
    "\n",
    "collisions_transformed_boolean = collisions_transformed.rdd.map(\n",
    "    lambda row: collisions_transformed_boolean_row(*([int(row.asDict()[c] > 0) if c in [\"Injured\",\n",
    "                                                \"Killed\"] else row.asDict()[c]\n",
    "                                                      for c in list(collisions_transformed_row)] + \n",
    "                                                    [row.Injured, row.Killed])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_transformed_boolean.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "aggregation_columns = {x:\"sum\" for x in [\"AccidentsWithInjuries\", \"AccidentswithDeaths\",\n",
    "                                    \"Auto\", \"Bus\", \"Truck\", \"Taxi\", \"Other\", \"Injured\", \"Killed\"]}\n",
    "aggregation_columns.update({\"*\":\"count\"})\n",
    "\n",
    "collisions_grouped = collisions_transformed_boolean.toDF().groupBy(\n",
    "    \"Time\", \"Street\", \"Borough\").agg(aggregation_columns)\n",
    "\n",
    "# rename columns names\n",
    "for c in collisions_grouped.columns:\n",
    "    if c.startswith(\"sum\") or c.startswith(\"SUM\"):\n",
    "        collisions_grouped = collisions_grouped.withColumnRenamed(c, c[4:-1])\n",
    "    elif c.startswith(\"count\") or c.startswith(\"COUNT\"):\n",
    "        collisions_grouped = collisions_grouped.withColumnRenamed(c, \"NumberOfAccidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_grouped.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_final_row = pyspark.sql.Row(*([\"Year\", \"Month\", \"Day\", \"Hour\"] + collisions_grouped.columns[1:]))\n",
    "collisions_final = collisions_grouped.rdd.map(lambda row: collisions_final_row(*([row.Time.year, row.Time.month,\n",
    "                                                                              row.Time.day, row.Time.hour] +\n",
    "                                                                             [row.asDict()[x]\n",
    "                                                                              for x in collisions_final_row[4:]]))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "collisions_final.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Determine the streets with the most collisions\n",
    "\n",
    "Find the top ten streets in New York where the most vehicle collisions occurred. Display the results in a bar graph and as a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "collisions_final_df = collisions_final\n",
    "# Note the Spark DataFrame SQL-like methods available: groupBy, agg, sort (order by), limit\n",
    "# The result is converted to a Pandas DataFrame\n",
    "plottingdf = collisions_final_df.groupBy(\"Borough\", \"Street\").agg(F.sum(\"NumberOfAccidents\").alias(\"sum(NumberOfAccidents)\")).\\\n",
    "sort(F.desc('sum(NumberOfAccidents)')).limit(10).toPandas()\n",
    "\n",
    "plottingdf[['sum(NumberOfAccidents)']].plot(kind='barh', figsize=(11,7), legend=False)\n",
    "plt.title('Top 10 Streets with the most accidents', size=20)\n",
    "plt.xlabel('Count')\n",
    "plt.yticks(range(10), plottingdf['Street'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Now you can add the information about the top 10 streets into the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data1 = collisions_out_df[['Borough', 'Street', 'LATITUDE', 'LONGITUDE']].toPandas()\n",
    "\n",
    "collisions1 = data1[np.logical_and(data1['Street']=='atlanticav', data1['Borough']=='brooklyn')]\n",
    "collisions2 = data1[np.logical_and(data1['Street']=='northernblvd', data1['Borough']=='queens')]\n",
    "collisions3 = data1[np.logical_and(data1['Street']=='brdway', data1['Borough']=='manhattan')]\n",
    "collisions4 = data1[np.logical_and(data1['Street']=='flatbushav', data1['Borough']=='brooklyn')]\n",
    "collisions5 = data1[np.logical_and(data1['Street']=='queensblvd', data1['Borough']=='queens')]\n",
    "collisions6 = data1[np.logical_and(data1['Street']=='2av', data1['Borough']=='manhattan')]\n",
    "collisions7 = data1[np.logical_and(data1['Street']=='hylanblvd', data1['Borough']=='staten island')]\n",
    "collisions8 = data1[np.logical_and(data1['Street']=='nostrandav', data1['Borough']=='brooklyn')]\n",
    "collisions9 = data1[np.logical_and(data1['Street']=='lindenblvd', data1['Borough']=='brooklyn')]\n",
    "collisions10 = data1[np.logical_and(data1['Street']=='bedfordav', data1['Borough']=='brooklyn')]\n",
    "\n",
    "#create scatterplots\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(data1.LONGITUDE, data1.LATITUDE, s=1, color='darkseagreen')\n",
    "plt.scatter(collisions1.LONGITUDE, collisions1.LATITUDE, s=2, color='red')\n",
    "plt.scatter(collisions2.LONGITUDE, collisions2.LATITUDE, color='blue', s=2)\n",
    "plt.scatter(collisions3.LONGITUDE, collisions3.LATITUDE, s=2, color='magenta')\n",
    "plt.scatter(collisions4.LONGITUDE, collisions4.LATITUDE, color='orange', s=2)\n",
    "plt.scatter(collisions5.LONGITUDE, collisions5.LATITUDE, s=2, color='yellow')\n",
    "plt.scatter(collisions6.LONGITUDE, collisions6.LATITUDE, color='purple', s=2)\n",
    "plt.scatter(collisions7.LONGITUDE, collisions7.LATITUDE, s=2, color='black')\n",
    "plt.scatter(collisions8.LONGITUDE, collisions8.LATITUDE, color='chartreuse', s=2)\n",
    "plt.scatter(collisions9.LONGITUDE, collisions9.LATITUDE, s=2, color='brown')\n",
    "plt.scatter(collisions10.LONGITUDE, collisions10.LATITUDE, color='darkgreen', s=2)\n",
    "\n",
    "\n",
    "#create legend\n",
    "a_patch = mpatches.Patch(color='red', label='Atlantic Avenue')\n",
    "b_patch = mpatches.Patch(color='blue', label='Northern Boulevard')\n",
    "c_patch = mpatches.Patch(color='magenta', label='Broadway')\n",
    "d_patch = mpatches.Patch(color='orange', label='Flatbush Avenue')\n",
    "e_patch = mpatches.Patch(color='yellow', label='Queens Boulevard')\n",
    "f_patch = mpatches.Patch(color='purple', label='2nd Avenue')\n",
    "g_patch = mpatches.Patch(color='black', label='Hylan Boulevard')\n",
    "h_patch = mpatches.Patch(color='chartreuse', label='Nostrand Avenue')\n",
    "i_patch = mpatches.Patch(color='brown', label='Linden Boulevard')\n",
    "j_patch = mpatches.Patch(color='darkgreen', label='Bedford Avenue')\n",
    "\n",
    "plt.legend([a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, h_patch, i_patch, j_patch],\n",
    "           ('Atlantic Avenue', 'Northern Boulevard', 'Broadway', 'Flatbush Avenue', 'Queens Boulevard', '2nd Avenue',\n",
    "            'Hylan Boulevard', 'Nostrand Avenue', 'Linden Boulevard', 'Bedford Avenue'), \n",
    "           loc='upper left', prop={'size':20})\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Vehicle Collisions in New York City', size=25)\n",
    "plt.xlim((-74.26,-73.7))\n",
    "plt.ylim((40.5,40.92))\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Determining when the most collisions occurred\n",
    "Now find out at what time of the day the most accidents occurred and see if you can detect any interesting patterns by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "hourplot = collisions_final_df[['Bus','Truck','Taxi','Other','Hour','Auto']].groupBy('Hour')\\\n",
    ".agg(F.sum(\"Bus\").alias(\"Bus\"), F.sum(\"Truck\").alias(\"Truck\"), F.sum(\"Taxi\").alias(\"Taxi\"),\\\n",
    "F.sum(\"Other\").alias(\"Other\"),F.sum(\"Auto\").alias(\"Auto\")).toPandas()\n",
    "\n",
    "hourplot[['Bus', 'Truck', 'Taxi', 'Auto']].plot(stacked=True, kind='bar',figsize=(12,8), alpha=1)\n",
    "#'SUM(Other)',\n",
    "plt.xlabel('Hour', size=17)\n",
    "plt.ylabel('Vehicles', size=17)\n",
    "plt.legend(loc='best', prop={'size':20}, framealpha=0) \n",
    "plt.title('Collisions on Road per Hour', size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This plot shows collisions spread across a day, with peaks during the morning and afternoon rush hours. You can see that significantly more collisions occurred during the afternoon rush hour than during the morning rush hour. Also, the most collisions involve cars by far, while buses, taxis, and trucks are involved in accidents a lot less frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "This notebook showed you how to analyze car vehicle accidents based on accident reports for New York and how you can use this information to learn more about the causes for collisions. If you extract  this type of information from the data, you can use it to help develop measures for preventing  vehicle accidents in accident hotspots.\n",
    "\n",
    "### Author\n",
    "The original notebook was created by Sven Hafeneger, a member of the Watson Studio development team at IBM Analytics in Germany. He holds a M.Sc. in Bioinformatics and is passionate about data analysis, machine learning and the Python ecosystem for data science. \n",
    "\n",
    "Copyright Â© IBM Corp. 2016, 2017. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python2.7 with Watson Studio Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
