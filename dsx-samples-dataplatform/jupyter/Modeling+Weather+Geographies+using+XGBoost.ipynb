{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling Weather Geographies using XGBoost\n",
    "\n",
    "In this notebook, we are using aggregated `TMAX` data by global weather stations in order to create a machine learning model to predict the daily maximum temperatures at any given latitude and longitude. Our model will take 3 continuous predictors: latitude, longitude, and elevation, and provide an estimated `TMAX` for a given day of the year.\n",
    "\n",
    "Finally, we will show how to save this model to your Watson Studio filesystem to be used for online scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Note: You will need to install the Basemap and GEOS libraries to dynamically produce output maps. For your convinience, the maps have been pre-rendered in this sample notebook.</div>\n",
    "\n",
    "## Table of Contents\n",
    "This notebook contains these main sections:\n",
    "\n",
    "1. [Import Libraries](#Import_Libraries)\n",
    "2. [The Data](#The_Data)\n",
    "3. [The Model](#The_Model)\n",
    "4. [Data Visualization](#Data_Visualization)\n",
    "5. [Save Model to Watson Studio Filesystem](#Save_Model_to_Watson_Studio_Filesystem)\n",
    "6. [Predict on New Data](#Predict_on_New_Data)\n",
    "7. [Summary](#Summary)\n",
    "\n",
    "<a id='Import_Libraries'></a>\n",
    "## Import Libraries\n",
    "Run the cell below once to install the `tqdm` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#from mpl_toolkits.basemap import Basemap, maskoceans\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='The_Data'></a>\n",
    "## The Data\n",
    "The dataset was created using data from the Global Historical Climatology Network. We have averaged the `TMAX` over the entire history of each weather station for the spring and autumn equinox, and the summer and winter solstice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_data_1 = pd.read_csv(\"https://raw.githubusercontent.com/IBMDataScience/DSX-DemoCenter/master/weatherGeographies/data_assets/seasonal_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's pull out the data from Boston's Logan International Airport:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>21-Mar</th>\n",
       "      <th>21-Jun</th>\n",
       "      <th>21-Sep</th>\n",
       "      <th>21-Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27094</th>\n",
       "      <td>USW00014739</td>\n",
       "      <td>42.3606</td>\n",
       "      <td>-71.0106</td>\n",
       "      <td>3.7</td>\n",
       "      <td>US</td>\n",
       "      <td>BOSTON LOGAN INTL AP</td>\n",
       "      <td>MA</td>\n",
       "      <td>7.690244</td>\n",
       "      <td>25.507407</td>\n",
       "      <td>21.975309</td>\n",
       "      <td>3.892593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  latitude  longitude  elevation country  \\\n",
       "27094  USW00014739   42.3606   -71.0106        3.7      US   \n",
       "\n",
       "                       name state    21-Mar     21-Jun     21-Sep    21-Dec  \n",
       "27094  BOSTON LOGAN INTL AP    MA  7.690244  25.507407  21.975309  3.892593  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_1[df_data_1['name'].str.contains('BOSTON LOGAN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As shown above, we have the lat-lon coordinates, and elevation data for the station. The last four columns determine the average daily maximum temperatures over the history of the station in Celsius. For example, the average `TMAX` on the 21st of June over all the recorded history for Logan Airport's weather station is 25.5$^{\\circ}$C.\n",
    "\n",
    "<a id='The_Model'></a>\n",
    "## The Model\n",
    "Let's first split the data by columns into features and response variables, and then further into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = df_data_1[['elevation','latitude','longitude']]\n",
    "y = df_data_1[['21-Mar','21-Jun','21-Sep','21-Dec']]\n",
    "\n",
    "x_init, x_test, y_init, y_test = train_test_split(x, y['21-Jun'], test_size=.25)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_init, y_init, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will fit a **XGBoost** model. XGBoost is an advanced implementation of the gradient boosting algorithm. XGBoost uses its own data structure called a `DMatrix` in which the training and testing data is stored. We can create a DMatrix below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:17.3622\n",
      "Will train until Test-mae hasn't improved in 1 rounds.\n",
      "[1]\tTest-mae:12.1576\n",
      "[2]\tTest-mae:8.5344\n",
      "[3]\tTest-mae:6.03006\n",
      "[4]\tTest-mae:4.3361\n",
      "[5]\tTest-mae:3.2276\n",
      "[6]\tTest-mae:2.51321\n",
      "[7]\tTest-mae:2.06199\n",
      "[8]\tTest-mae:1.78793\n",
      "[9]\tTest-mae:1.62618\n",
      "[10]\tTest-mae:1.51968\n",
      "[11]\tTest-mae:1.45972\n",
      "[12]\tTest-mae:1.42318\n",
      "[13]\tTest-mae:1.38381\n",
      "[14]\tTest-mae:1.3684\n",
      "[15]\tTest-mae:1.35151\n",
      "[16]\tTest-mae:1.34271\n",
      "[17]\tTest-mae:1.33646\n",
      "[18]\tTest-mae:1.32589\n",
      "[19]\tTest-mae:1.32184\n",
      "[20]\tTest-mae:1.31396\n",
      "[21]\tTest-mae:1.30195\n",
      "[22]\tTest-mae:1.3003\n",
      "[23]\tTest-mae:1.29365\n",
      "[24]\tTest-mae:1.28396\n",
      "[25]\tTest-mae:1.27956\n",
      "[26]\tTest-mae:1.27445\n",
      "[27]\tTest-mae:1.27331\n",
      "[28]\tTest-mae:1.27344\n",
      "Stopping. Best iteration:\n",
      "[27]\tTest-mae:1.27331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dval = xgb.DMatrix(x_val, label=y_val)\n",
    "dtest = xgb.DMatrix(x_test, label = y_test)\n",
    "\n",
    "val_model = xgb.train(params = {'eval_metric':'mae'}, \n",
    "                      dtrain = dtrain, \n",
    "                      num_boost_round=200,\n",
    "                      evals=[(dval, \"Test\")],\n",
    "                      early_stopping_rounds=1,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Unlike our `scikit-learn` implementation of gradient boosting, XGBoost automatically determines the ideal number of boosting rounds depending on whether improvement to a particular evaluation metric (in our case, *mean absolute error*) no longer improves. Below we can print the best number of iterations to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.2920784997\n",
      "R^2 value: 0.834500839387\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params = {'eval_metric':'mae'}, \n",
    "                  dtrain = dtrain, \n",
    "                  num_boost_round=26,\n",
    "                  evals=[(dtest, \"Test\")],\n",
    "                  verbose_eval = False)\n",
    "y_pred = model.predict(dtest)\n",
    "print(\"Mean Absolute Error: {}\\nR^2 value: {}\".format(mean_absolute_error(y_test,y_pred),r2_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Not bad! Remember that we are dealing with degrees Celsius. Our mean error in this case around less than 2 degrees. We also have a strong $R^2$ value.\n",
    "\n",
    "Now let's fit the models on the entirety of the data, and then produce a grid of predicted `TMAX` values to visualize on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "june_data = xgb.DMatrix(x, label=y['21-Jun'])\n",
    "xgb_jun = xgb.train(params = {}, dtrain = june_data, num_boost_round=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And now the model for the December 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dec_data = xgb.DMatrix(x, label=y['21-Dec'])\n",
    "xgb_dec = xgb.train(params = {}, dtrain = dec_data, num_boost_round=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Data_Visualization'></a>\n",
    "## Data Visualization\n",
    "Let's pull a matrix of elevation data. The data will contain elevations at latitudes [-90,90], every degree and longitudes [-180,180), every 2 degrees. We'll provide the latitude, longitude, and elevation from this matrix to create a matrix of the same size that contains predicted temperature information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "z = pd.DataFrame(np.empty([181,180]))\n",
    "elevations = pd.read_csv(\"https://raw.githubusercontent.com/IBMDataScience/DSX-DemoCenter/master/weatherGeographies/data_assets/elevation.csv\", index_col=0)\n",
    "\n",
    "# Make sure that the matrices are indexed by (lon,lat) values\n",
    "elevations.columns = elevations.columns.astype(int)\n",
    "z.columns = elevations.columns\n",
    "z.index = elevations.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plots\n",
    "We'll use `matplotlib` Basemap to plot our data. First, we should fill our empty `z` temperature matrix with the predicted temperatures. Then we must flip the matrix, as Basemap wants 90$^{\\circ}$S to be the first row in the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> If you have installed the Basemap and GEOS libraries, copy the code below in a python cell to dynamically produce an output map</div>\n",
    "\n",
    "```python\n",
    "for lon in range(-180,180,2):\n",
    "    for lat in reversed(range(-90,91,1)):\n",
    "        z[lon][lat] = xgb_jun.predict(xgb.DMatrix(pd.DataFrame({\n",
    "            \"latitude\": [lat],\n",
    "            \"longitude\": [lon],\n",
    "            \"elevation\": [elevations[lon][lat]]\n",
    "        })))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,15)\n",
    "m = Basemap()\n",
    "lon, lat = np.meshgrid(list(range(-180,180,2)),list(range(-90,91,1)))\n",
    "x1,y1 = m(lon,lat)\n",
    "m.drawcoastlines()\n",
    "m.drawstates()\n",
    "m.drawcountries()\n",
    "m.drawmapboundary()\n",
    "z1 = maskoceans(x1,y1,np.flip(np.array(z),axis=0))\n",
    "cs = m.contourf(x1,y1,z1, 15)\n",
    "plt.show()\n",
    "```\n",
    "![](https://github.com/IBMDataScience/DSX-DemoCenter/raw/master/weatherGeographies/notebooks/static/jun21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a fairly predictable distribution of temperatures for the 21st of June. Africa and the southern United States are scortching hot, while Antarctica is frigidly cold. Elevation data has also proved to be important, as the himalayas and tibet are marked to be colder than other regions at the same latitude, just as expected. It would be interesting to see how our map would differ if we used 21st of December data:\n",
    "\n",
    "```python\n",
    "for lon in range(-180,180,2):\n",
    "    for lat in reversed(range(-90,91,1)):\n",
    "        z[lon][lat] = xgb_dec.predict(xgb.DMatrix(pd.DataFrame({\n",
    "            \"latitude\": [lat],\n",
    "            \"longitude\": [lon],\n",
    "            \"elevation\": [elevations[lon][lat]]\n",
    "        })))\n",
    "\n",
    "m = Basemap()\n",
    "lon, lat = np.meshgrid(list(range(-180,180,2)),list(range(-90,91,1)))\n",
    "x1,y1 = m(lon,lat)\n",
    "m.drawcoastlines()\n",
    "m.drawstates()\n",
    "m.drawcountries()\n",
    "m.drawmapboundary()\n",
    "z1 = maskoceans(x1,y1,np.flip(np.array(z),axis=0))\n",
    "cs = m.contourf(x1,y1,z1, 15)\n",
    "plt.show()\n",
    "```\n",
    "![](https://github.com/IBMDataScience/DSX-DemoCenter/raw/master/weatherGeographies/notebooks/static/dec21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The model has done an excellent job in estimating the temperatures on 21-Dec. As expected, the southern hemisphere is in summer, and thus hot, while North America and Europe are in Winter. \n",
    "\n",
    "<a id='Save_Model_to_Watson_Studio_Filesystem'></a>\n",
    "## Save Model to Watson Studio Filesystem\n",
    "We can now save `XGBoost` models to the Watson Studio filesystem for publishing, scoring, deployment, and evaluations. First, import the `save` function from the `dsx_ml.ml` library. The save function takes a few arguments which are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dsx_ml.ml import save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can save both the June 21 and December 21 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/user-home/999/DSX_Projects/dsx-samples/models/XGBJune21/1',\n",
       " 'scoring_endpoint': 'https://dsxl-api/v3/project/score/Python27/xgboost-0.7/dsx-samples/XGBJune21/1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save(model = xgb_jun,\n",
    "     name = 'XGBJune21',\n",
    "     x_test = x,\n",
    "     y_test = pd.DataFrame(y['21-Jun']),\n",
    "     algorithm_type = 'Regression',\n",
    "     params = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/user-home/999/DSX_Projects/dsx-samples/models/XGBDec21/1',\n",
       " 'scoring_endpoint': 'https://dsxl-api/v3/project/score/Python27/xgboost-0.7/dsx-samples/XGBDec21/1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save(model = xgb_dec,\n",
    "     name = 'XGBDec21',\n",
    "     x_test = x,\n",
    "     y_test = pd.DataFrame(y['21-Dec']),\n",
    "     algorithm_type = 'Regression',\n",
    "     params = {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Metadata\n",
    "The model will be stored in the models directory in your Watson Studio Project. Each model is stored as a directory, in which the model artifact and metadata are stored. The metadata is stored as a JSON file, which we can open and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: Python27\n",
      "Model Type: xgboost-0.7\n",
      "Algorithm: Booster\n",
      "Feature(s):\n",
      "    elevation\n",
      "    latitude\n",
      "    longitude\n",
      "Latest Model Version: 1\n",
      "Label(s):\n",
      "    21-Dec\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "uid = os.environ['DSX_USER_ID']\n",
    "proj = os.environ['DSX_PROJECT_NAME']\n",
    "\n",
    "with open('/user-home/{}/DSX_Projects/{}/models/XGBDec21/metadata.json'.format(uid,proj),'r') as infile:\n",
    "    metadata_dict = json.load(infile)\n",
    "\n",
    "print(\"Runtime: {}\".format(metadata_dict['runtime']))\n",
    "print(\"Model Type: {}\".format(metadata_dict['type']))\n",
    "print(\"Algorithm: {}\".format(metadata_dict['algorithm']))\n",
    "\n",
    "print(\"Feature(s):\")\n",
    "for feature in metadata_dict['features']:\n",
    "    print('    '+feature['name'])\n",
    "\n",
    "print(\"Latest Model Version: {}\".format(metadata_dict['latestModelVersion']))\n",
    "print(\"Label(s):\")\n",
    "for label in metadata_dict['labelColumns']:\n",
    "    print('    '+label['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Predict_on_New_Data'></a>\n",
    "## Predict on New Data\n",
    "\n",
    "Let's make some predictions using new data. Below we have gathered the latitude, longitude, and elevation data for the cities of Chicago, IL and Miami, FL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "chicago_data = {\n",
    "    \"elevation\" : 200.6,\n",
    "    \"latitude\" : 41.995,\n",
    "    \"longitude\" : -87.9336\n",
    "}\n",
    "\n",
    "miami_data = {\n",
    "    \"elevation\" : 1,\n",
    "    \"latitude\" : 25.7616798,\n",
    "    \"longitude\" : -80.1917902\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can call the predict function of our models and print them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On June 21, it is predicted to be 27.0° C in Chicago, and 31.9° C in Miami\n",
      "On December 21, it is predicted to be 1.6° C in Chicago, and 24.3° C in Miami\n"
     ]
    }
   ],
   "source": [
    "new_data = xgb.DMatrix(pd.DataFrame([chicago_data, miami_data]))\n",
    "\n",
    "jun21_temps = xgb_jun.predict(new_data)\n",
    "dec21_temps = xgb_dec.predict(new_data)\n",
    "\n",
    "\n",
    "output_str = (u'On June 21, it is predicted to be ' +\n",
    "    str(jun21_temps[0].round(1)) + \n",
    "    u'\\N{DEGREE SIGN} C in Chicago, and '+ \n",
    "    str(jun21_temps[1].round(1)) + \n",
    "    u'\\N{DEGREE SIGN} C in Miami\\n' + \n",
    "    u'On December 21, it is predicted to be ' + \n",
    "    str(dec21_temps[0].round(1)) + \n",
    "    u'\\N{DEGREE SIGN} C in Chicago, and ' + \n",
    "    str(dec21_temps[1].round(1)) +\n",
    "    u'\\N{DEGREE SIGN} C in Miami')\n",
    "\n",
    "\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='Summary'></a>\n",
    "## Summary\n",
    "In this notebook you learned how to create an XGBoost `Booster` model, create some data visualizations, and save the model in the Watson Studio environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">Note: To save resources and get the best performance please use the code below to stop the kernel before exiting your notebook.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2017. Released as licensed Sample Materials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with Watson Studio Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
